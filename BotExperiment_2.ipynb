{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dad0b46-516f-413d-8464-9f39193d6760",
   "metadata": {},
   "source": [
    "# Experiment 2 - Compare embeddings, home grown vs Open AI or Open Source\n",
    "\n",
    "Objective: Determine if open source or OpenAI embeddings can yield similar outcomes as high-end embeddings in RAG.\n",
    "\n",
    "Before even getting to RAG, we will just do a comparison with cosine similarity measures to see how close we get. \n",
    "\n",
    "## Setup, imports, logging, keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12892943-9440-4a51-b7b5-2ba389059213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import openai\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import logging\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "\n",
    "# delete log file if exists to start fresh\n",
    "log_file_path = 'exp_2.log'\n",
    "\n",
    "if os.path.exists(log_file_path):\n",
    "    os.remove(log_file_path)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename=log_file_path, mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31acfed7-69c3-4ffb-9b18-83a9170f89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f09e296-299d-4c5e-8660-ce3b1776b777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86986973-7e0c-426d-affe-0eb585c58fcc",
   "metadata": {},
   "source": [
    "# Step 1 - Create OpenAI ada embeddings using the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fd6eef6-7906-4cd8-9f8a-75894cd13086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   \n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    retry_count = 0\n",
    "    max_retries = 4\n",
    "    wait_time = 7  # Initial wait time in seconds\n",
    "\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            logger.debug(f\"Try to embed: {text}\")\n",
    "            embedding = openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "            return embedding\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)[:30]}\")\n",
    "            print(f\"Retrying in {wait_time} seconds...\")\n",
    "\n",
    "            logger.debug(f\"An error occurred: {str(e)[:30]}\")\n",
    "            logger.debug(f\"Retrying in {wait_time} seconds...\")\n",
    "            \n",
    "            time.sleep(wait_time)\n",
    "            retry_count += 1\n",
    "            wait_time *= 3  # Exponential backoff: double the wait time for each retry\n",
    "\n",
    "    print(\"Exceeded maximum number of retries. Aborting.\")\n",
    "    logger.debug(\"Exceeded maximum number of retries. Aborting.\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57085936-f3d1-4555-a0c2-2a2e549dc57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bot_question_intent_map.csv')\n",
    "len(df)\n",
    "\n",
    "seen_questions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71b5dbbc-7bb0-4cc2-b8d7-5baa4263863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for the original question\n",
    "df['question_embedding'] = df.apply(lambda row: get_embedding(row['question']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebaf7af8-69d6-4175-bf45-94c551a20983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for the intent question\n",
    "df['intent_embedding'] = df.apply(lambda row: get_embedding(row['intent question']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe21386-6ae9-4227-9e15-b7467512c45f",
   "metadata": {},
   "source": [
    "# Step 2 - Calcualte the similarity and persist in a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc5ed187-2638-4190-9916-223710a6caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance\n",
    "df['embedding_distance'] = df.apply(lambda row: cosine_similarity(row['question_embedding'], row['intent_embedding']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d842ff02-f0d4-41c5-96da-191b086a0031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings\n",
    "df.to_csv('bot_questions_embeddigns_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dab367-1e89-4a4d-b5f3-293e3dcee7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62218e0-6e42-4616-b744-0d6457701fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ca3d3-1720-45a1-8fb5-c42558ce3d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
